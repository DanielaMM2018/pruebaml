# Prueba Puntos Colombia

Descripci√≥n de los archivos y carpetas m√°s relevantes del proyecto.

## Estructura y explicaci√≥n

- data/
  - `muestra_transacciones.csv` - muestra de transacciones (id_cliente, fecha, valor_transaccion, categoria, puntos, tipo_transaccion, id_transaccion, ...).
  - `muestra_customers.csv` - informaci√≥n de clientes (id_cliente, fecha_nacimiento, genero, saldo_puntos, ...).

- notebooks/
  - `01_eda.py` - script de EDA que genera gr√°ficos en `results/eda` (distribuciones, recencia, histogramas, etc.).
  - `021_feature_engineering.py` - genera features a nivel usuario y guarda `results/features/features_usuarios_final.csv`.
  - `022_correlation_matrix.py` - calcula y guarda la matriz de correlaci√≥n (`results/features/correlation_matrix_full.csv`) y un heatmap (`correlation_matrix_full.png`).
  - `023_correlation_redundancy.py` - detecta features redundantes (umbral 0.90), guarda `features_sin_redundancia.csv` y `high_correlation_pairs.csv`.

- results/
  - `eda/` - gr√°ficos resultantes del EDA.
  - `features/` - features intermedios y finales, matrices de correlaci√≥n y pares de alta correlaci√≥n.

- `requirements.txt` - listado de dependencias; usar para instalar el entorno.

## Flujo de trabajo recomendado

1. Preparar entorno y dependencias.
2. Ejecutar `01_eda.py` para inspeccionar los datos.
3. Ejecutar `021_feature_engineering.py` para crear `features_usuarios_final.csv`.
4. Ejecutar `022_correlation_matrix.py` y `023_correlation_redundancy.py` para identificar redundancias y limpiar features.
5. Ejecutar notebooks de clustering (`03x`) y modelado (`04x`) para evaluar y comparar modelos.

## Notas

- Los artefactos (CSVs, PNGs) se guardan en `results/` para mantener reproducibilidad.

---

## Documentaci√≥n & Gu√≠as üìö

- `notebooks/FEATURE.MD` - Gu√≠a detallada de la ingenier√≠a de features: transformaciones, selecci√≥n, variables finales y recomendaciones para escalado y reducci√≥n de dimensionalidad.
- `notebooks/SUPERVISED.MD` - Documentaci√≥n del modelado supervisado (objetivo ordinal para categor√≠a TECNOLOG√çA), algoritmos evaluados y m√©tricas de evaluaci√≥n.
- `notebooks/CLUSTERING.MD` - Reporte de los experimentos de clustering (K-Means, Birch, Agglomerative), selecci√≥n de K y perfiles resultantes.
- `sage_maker_scripts/SAGEMAKER.MD` - Dise√±o y flujo para entrenamiento y registro en SageMaker, estructura de artefactos en S3 y pasos de despliegue.

---

## Revisi√≥n general del proyecto ‚úÖ

**Alcance:** Construcci√≥n de un pipeline reproducible para generaci√≥n de features, segmentaci√≥n (clustering) y modelado ordinal de la intensidad de compra en la categor√≠a *TECNOLOG√çA*.

**Fortalezas:**
- Pipeline modular y reproducible; artefactos bien organizados (`results/`, `artifacts/`, `models/`).
- Documentaci√≥n t√©cnica en m√∫ltiples MDs que facilitan replicaci√≥n y revisi√≥n.
- Enfoque t√©cnico s√≥lido: features temporales, tratamiento de outliers y objetivo ordinal apropiado.

**√Åreas de mejora / pr√≥ximos pasos:**
- A√±adir tests autom√°ticos (unitarios para transformaciones, integraciones para pipelines).
- Automatizar ejecuci√≥n (Makefile / CI) para reproducibilidad continua.
- Incluir ejemplos de uso y notebooks de inferencia/serving.
- Registrar m√°s claramente los contratos de entrada/salida de cada script (schemas de CSV).

**C√≥mo empezar a contribuir:**
1. Instalar dependencias: `pip install -r requirements.txt`.
2. Reproducir feature engineering: `python notebooks/021_feature_engineering.py`.
3. Ejecutar modelos: `python notebooks/042_supervised_xgboost_ordinal.py` y notebooks de clustering en `03x`.
4. Abrir los MDs mencionados para entender decisiones y par√°metros.


